{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder + Classifier for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "from torchvision import datasets, models, transforms     # vision datasets,\n",
    "                                                         # architectures &\n",
    "                                                         # transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms              # composable transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./ae_v2_img'):\n",
    "    os.mkdir('./ae_v2_img')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "full_trainset = datasets.MNIST(root='./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "\n",
    "len_train = int(0.8 * len(full_trainset))\n",
    "len_val = len(full_trainset) - len_train\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(full_trainset, [len_train, len_val]) \n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set = datasets.MNIST(root='./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x189f097df48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "images, labels = iter(train_loader).next()\n",
    "img = images[0][0].numpy()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, bottleneck = 8):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(nn.Linear(784, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(64, 16), \n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(16, bottleneck),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.Linear(bottleneck, 16),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(16, 32),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(32, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 784),\n",
    "                                    nn.Tanh())\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(bottleneck, 64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64, 32),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(32, 10),\n",
    "                                        nn.LogSoftmax(dim=1))\n",
    "        self.config = \"decoder\"\n",
    "        \n",
    "    def forward(self, x,):\n",
    "        encoded = self.encoder(x)\n",
    "        if self.config==\"decoder\":\n",
    "            out = self.decoder(encoded)\n",
    "        elif self.config==\"classifier\":\n",
    "            out = self.classifier(encoded)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "            return\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], \tTraining Loss:34.1727 \tValidation Loss:26.7879\n",
      "Validation loss has decreased (inf-->26.7879). Model saved...\n",
      "epoch [2/100], \tTraining Loss:22.6031 \tValidation Loss:19.8073\n",
      "Validation loss has decreased (26.7879-->19.8073). Model saved...\n",
      "epoch [3/100], \tTraining Loss:18.8241 \tValidation Loss:18.1555\n",
      "Validation loss has decreased (19.8073-->18.1555). Model saved...\n",
      "epoch [4/100], \tTraining Loss:17.2469 \tValidation Loss:16.5161\n",
      "Validation loss has decreased (18.1555-->16.5161). Model saved...\n",
      "epoch [5/100], \tTraining Loss:15.9202 \tValidation Loss:15.6468\n",
      "Validation loss has decreased (16.5161-->15.6468). Model saved...\n",
      "epoch [6/100], \tTraining Loss:15.2455 \tValidation Loss:15.1638\n",
      "Validation loss has decreased (15.6468-->15.1638). Model saved...\n",
      "epoch [7/100], \tTraining Loss:14.8267 \tValidation Loss:14.8243\n",
      "Validation loss has decreased (15.1638-->14.8243). Model saved...\n",
      "epoch [8/100], \tTraining Loss:14.5097 \tValidation Loss:14.4982\n",
      "Validation loss has decreased (14.8243-->14.4982). Model saved...\n",
      "epoch [9/100], \tTraining Loss:14.2579 \tValidation Loss:14.3150\n",
      "Validation loss has decreased (14.4982-->14.3150). Model saved...\n",
      "epoch [10/100], \tTraining Loss:13.9970 \tValidation Loss:14.0124\n",
      "Validation loss has decreased (14.3150-->14.0124). Model saved...\n",
      "epoch [11/100], \tTraining Loss:13.6629 \tValidation Loss:13.6754\n",
      "Validation loss has decreased (14.0124-->13.6754). Model saved...\n",
      "epoch [12/100], \tTraining Loss:13.3484 \tValidation Loss:13.3568\n",
      "Validation loss has decreased (13.6754-->13.3568). Model saved...\n",
      "epoch [13/100], \tTraining Loss:13.0628 \tValidation Loss:13.1670\n",
      "Validation loss has decreased (13.3568-->13.1670). Model saved...\n",
      "epoch [14/100], \tTraining Loss:12.8287 \tValidation Loss:12.8226\n",
      "Validation loss has decreased (13.1670-->12.8226). Model saved...\n",
      "epoch [15/100], \tTraining Loss:12.5659 \tValidation Loss:12.6094\n",
      "Validation loss has decreased (12.8226-->12.6094). Model saved...\n",
      "epoch [16/100], \tTraining Loss:12.2881 \tValidation Loss:12.3140\n",
      "Validation loss has decreased (12.6094-->12.3140). Model saved...\n",
      "epoch [17/100], \tTraining Loss:12.0399 \tValidation Loss:12.0507\n",
      "Validation loss has decreased (12.3140-->12.0507). Model saved...\n",
      "epoch [18/100], \tTraining Loss:11.8593 \tValidation Loss:11.9415\n",
      "Validation loss has decreased (12.0507-->11.9415). Model saved...\n",
      "epoch [19/100], \tTraining Loss:11.6914 \tValidation Loss:11.8087\n",
      "Validation loss has decreased (11.9415-->11.8087). Model saved...\n",
      "epoch [20/100], \tTraining Loss:11.5508 \tValidation Loss:11.6983\n",
      "Validation loss has decreased (11.8087-->11.6983). Model saved...\n",
      "epoch [21/100], \tTraining Loss:11.4241 \tValidation Loss:11.5538\n",
      "Validation loss has decreased (11.6983-->11.5538). Model saved...\n",
      "epoch [22/100], \tTraining Loss:11.3225 \tValidation Loss:11.4198\n",
      "Validation loss has decreased (11.5538-->11.4198). Model saved...\n",
      "epoch [23/100], \tTraining Loss:11.2089 \tValidation Loss:11.3453\n",
      "Validation loss has decreased (11.4198-->11.3453). Model saved...\n",
      "epoch [24/100], \tTraining Loss:11.1164 \tValidation Loss:11.4074\n",
      "epoch [25/100], \tTraining Loss:11.0465 \tValidation Loss:11.2467\n",
      "Validation loss has decreased (11.3453-->11.2467). Model saved...\n",
      "epoch [26/100], \tTraining Loss:10.9563 \tValidation Loss:11.1263\n",
      "Validation loss has decreased (11.2467-->11.1263). Model saved...\n",
      "epoch [27/100], \tTraining Loss:10.9029 \tValidation Loss:11.0902\n",
      "Validation loss has decreased (11.1263-->11.0902). Model saved...\n",
      "epoch [28/100], \tTraining Loss:10.8362 \tValidation Loss:10.9892\n",
      "Validation loss has decreased (11.0902-->10.9892). Model saved...\n",
      "epoch [29/100], \tTraining Loss:10.7690 \tValidation Loss:10.9246\n",
      "Validation loss has decreased (10.9892-->10.9246). Model saved...\n",
      "epoch [30/100], \tTraining Loss:10.7221 \tValidation Loss:10.8933\n",
      "Validation loss has decreased (10.9246-->10.8933). Model saved...\n",
      "epoch [31/100], \tTraining Loss:10.6696 \tValidation Loss:10.8464\n",
      "Validation loss has decreased (10.8933-->10.8464). Model saved...\n",
      "epoch [32/100], \tTraining Loss:10.6264 \tValidation Loss:10.7998\n",
      "Validation loss has decreased (10.8464-->10.7998). Model saved...\n",
      "epoch [33/100], \tTraining Loss:10.5678 \tValidation Loss:10.7440\n",
      "Validation loss has decreased (10.7998-->10.7440). Model saved...\n",
      "epoch [34/100], \tTraining Loss:10.5280 \tValidation Loss:10.7030\n",
      "Validation loss has decreased (10.7440-->10.7030). Model saved...\n",
      "epoch [35/100], \tTraining Loss:10.4791 \tValidation Loss:10.7284\n",
      "epoch [36/100], \tTraining Loss:10.4371 \tValidation Loss:10.6742\n",
      "Validation loss has decreased (10.7030-->10.6742). Model saved...\n",
      "epoch [37/100], \tTraining Loss:10.4128 \tValidation Loss:10.6527\n",
      "Validation loss has decreased (10.6742-->10.6527). Model saved...\n",
      "epoch [38/100], \tTraining Loss:10.3593 \tValidation Loss:10.5624\n",
      "Validation loss has decreased (10.6527-->10.5624). Model saved...\n",
      "epoch [39/100], \tTraining Loss:10.3232 \tValidation Loss:10.5864\n",
      "epoch [40/100], \tTraining Loss:10.3078 \tValidation Loss:10.5581\n",
      "Validation loss has decreased (10.5624-->10.5581). Model saved...\n",
      "epoch [41/100], \tTraining Loss:10.2793 \tValidation Loss:10.5008\n",
      "Validation loss has decreased (10.5581-->10.5008). Model saved...\n",
      "epoch [42/100], \tTraining Loss:10.2310 \tValidation Loss:10.4709\n",
      "Validation loss has decreased (10.5008-->10.4709). Model saved...\n",
      "epoch [43/100], \tTraining Loss:10.2134 \tValidation Loss:10.4503\n",
      "Validation loss has decreased (10.4709-->10.4503). Model saved...\n",
      "epoch [44/100], \tTraining Loss:10.1726 \tValidation Loss:10.4407\n",
      "Validation loss has decreased (10.4503-->10.4407). Model saved...\n",
      "epoch [45/100], \tTraining Loss:10.1635 \tValidation Loss:10.5587\n",
      "epoch [46/100], \tTraining Loss:10.1342 \tValidation Loss:10.3573\n",
      "Validation loss has decreased (10.4407-->10.3573). Model saved...\n",
      "epoch [47/100], \tTraining Loss:10.0992 \tValidation Loss:10.3198\n",
      "Validation loss has decreased (10.3573-->10.3198). Model saved...\n",
      "epoch [48/100], \tTraining Loss:10.0709 \tValidation Loss:10.3537\n",
      "epoch [49/100], \tTraining Loss:10.0456 \tValidation Loss:10.3708\n",
      "epoch [50/100], \tTraining Loss:10.0396 \tValidation Loss:10.2176\n",
      "Validation loss has decreased (10.3198-->10.2176). Model saved...\n",
      "epoch [51/100], \tTraining Loss:10.0143 \tValidation Loss:10.2637\n",
      "epoch [52/100], \tTraining Loss:9.9849 \tValidation Loss:10.2440\n",
      "epoch [53/100], \tTraining Loss:9.9608 \tValidation Loss:10.1758\n",
      "Validation loss has decreased (10.2176-->10.1758). Model saved...\n",
      "epoch [54/100], \tTraining Loss:9.9450 \tValidation Loss:10.2034\n",
      "epoch [55/100], \tTraining Loss:9.9209 \tValidation Loss:10.2449\n",
      "epoch [56/100], \tTraining Loss:9.9112 \tValidation Loss:10.1574\n",
      "Validation loss has decreased (10.1758-->10.1574). Model saved...\n",
      "epoch [57/100], \tTraining Loss:9.8969 \tValidation Loss:10.1562\n",
      "Validation loss has decreased (10.1574-->10.1562). Model saved...\n",
      "epoch [58/100], \tTraining Loss:9.8693 \tValidation Loss:10.1132\n",
      "Validation loss has decreased (10.1562-->10.1132). Model saved...\n",
      "epoch [59/100], \tTraining Loss:9.8460 \tValidation Loss:10.0725\n",
      "Validation loss has decreased (10.1132-->10.0725). Model saved...\n",
      "epoch [60/100], \tTraining Loss:9.8334 \tValidation Loss:10.0774\n",
      "epoch [61/100], \tTraining Loss:9.8284 \tValidation Loss:10.1108\n",
      "epoch [62/100], \tTraining Loss:9.8051 \tValidation Loss:10.0649\n",
      "Validation loss has decreased (10.0725-->10.0649). Model saved...\n",
      "epoch [63/100], \tTraining Loss:9.7954 \tValidation Loss:10.0828\n",
      "epoch [64/100], \tTraining Loss:9.7677 \tValidation Loss:10.0385\n",
      "Validation loss has decreased (10.0649-->10.0385). Model saved...\n",
      "epoch [65/100], \tTraining Loss:9.7614 \tValidation Loss:10.0814\n",
      "epoch [66/100], \tTraining Loss:9.7562 \tValidation Loss:10.0313\n",
      "Validation loss has decreased (10.0385-->10.0313). Model saved...\n",
      "epoch [67/100], \tTraining Loss:9.7302 \tValidation Loss:10.0372\n",
      "epoch [68/100], \tTraining Loss:9.7253 \tValidation Loss:10.0427\n",
      "epoch [69/100], \tTraining Loss:9.7128 \tValidation Loss:10.0584\n",
      "epoch [70/100], \tTraining Loss:9.6956 \tValidation Loss:10.0168\n",
      "Validation loss has decreased (10.0313-->10.0168). Model saved...\n",
      "epoch [71/100], \tTraining Loss:9.6873 \tValidation Loss:9.9742\n",
      "Validation loss has decreased (10.0168-->9.9742). Model saved...\n",
      "epoch [72/100], \tTraining Loss:9.6706 \tValidation Loss:9.9472\n",
      "Validation loss has decreased (9.9742-->9.9472). Model saved...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [73/100], \tTraining Loss:9.6515 \tValidation Loss:9.9708\n",
      "epoch [74/100], \tTraining Loss:9.6559 \tValidation Loss:9.9460\n",
      "Validation loss has decreased (9.9472-->9.9460). Model saved...\n",
      "epoch [75/100], \tTraining Loss:9.6328 \tValidation Loss:9.9224\n",
      "Validation loss has decreased (9.9460-->9.9224). Model saved...\n",
      "epoch [76/100], \tTraining Loss:9.6351 \tValidation Loss:9.9389\n",
      "epoch [77/100], \tTraining Loss:9.6069 \tValidation Loss:9.8968\n",
      "Validation loss has decreased (9.9224-->9.8968). Model saved...\n",
      "epoch [78/100], \tTraining Loss:9.6049 \tValidation Loss:9.9262\n",
      "epoch [79/100], \tTraining Loss:9.5882 \tValidation Loss:9.9472\n",
      "epoch [80/100], \tTraining Loss:9.5831 \tValidation Loss:9.8822\n",
      "Validation loss has decreased (9.8968-->9.8822). Model saved...\n",
      "epoch [81/100], \tTraining Loss:9.5783 \tValidation Loss:9.9104\n",
      "epoch [82/100], \tTraining Loss:9.5514 \tValidation Loss:9.8738\n",
      "Validation loss has decreased (9.8822-->9.8738). Model saved...\n",
      "epoch [83/100], \tTraining Loss:9.5613 \tValidation Loss:9.8640\n",
      "Validation loss has decreased (9.8738-->9.8640). Model saved...\n",
      "epoch [84/100], \tTraining Loss:9.5392 \tValidation Loss:9.8977\n",
      "epoch [85/100], \tTraining Loss:9.5440 \tValidation Loss:9.8812\n",
      "epoch [86/100], \tTraining Loss:9.5220 \tValidation Loss:9.8519\n",
      "Validation loss has decreased (9.8640-->9.8519). Model saved...\n",
      "epoch [87/100], \tTraining Loss:9.5119 \tValidation Loss:9.8965\n",
      "epoch [88/100], \tTraining Loss:9.5089 \tValidation Loss:9.9100\n",
      "epoch [89/100], \tTraining Loss:9.5018 \tValidation Loss:9.8148\n",
      "Validation loss has decreased (9.8519-->9.8148). Model saved...\n",
      "epoch [90/100], \tTraining Loss:9.4745 \tValidation Loss:9.7963\n",
      "Validation loss has decreased (9.8148-->9.7963). Model saved...\n",
      "epoch [91/100], \tTraining Loss:9.4933 \tValidation Loss:9.8124\n",
      "epoch [92/100], \tTraining Loss:9.4687 \tValidation Loss:9.7779\n",
      "Validation loss has decreased (9.7963-->9.7779). Model saved...\n",
      "epoch [93/100], \tTraining Loss:9.4536 \tValidation Loss:9.9148\n",
      "epoch [94/100], \tTraining Loss:9.4612 \tValidation Loss:9.7666\n",
      "Validation loss has decreased (9.7779-->9.7666). Model saved...\n",
      "epoch [95/100], \tTraining Loss:9.4453 \tValidation Loss:9.7126\n",
      "Validation loss has decreased (9.7666-->9.7126). Model saved...\n",
      "epoch [96/100], \tTraining Loss:9.4433 \tValidation Loss:9.7672\n",
      "epoch [97/100], \tTraining Loss:9.4333 \tValidation Loss:9.7779\n",
      "epoch [98/100], \tTraining Loss:9.4438 \tValidation Loss:9.7857\n",
      "epoch [99/100], \tTraining Loss:9.4036 \tValidation Loss:9.7952\n",
      "epoch [100/100], \tTraining Loss:9.4131 \tValidation Loss:9.7782\n"
     ]
    }
   ],
   "source": [
    "val_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    model.train()\n",
    "    for image, label in train_loader:\n",
    "        image = image.view(image.size(0), -1)\n",
    "        #forward\n",
    "        out = model(image)\n",
    "        loss = criterion(out, image)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()*image.size(0)\n",
    "    \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        rep_pic = to_img(out)\n",
    "        save_image(rep_pic, './ae_v2_img/rep_image_{}.png'.format(epoch)) \n",
    "        original_pic = to_img(image)\n",
    "        save_image(original_pic,'./ae_v2_img/ori_image_{}.png'.format(epoch))\n",
    "        \n",
    "    model.eval()\n",
    "    for image, label in val_loader:\n",
    "        image = image.view(image.size(0), -1)\n",
    "        out = model(image)\n",
    "        loss = criterion(out, image)\n",
    "\n",
    "        val_loss += loss.item()*image.size(0)\n",
    "        \n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    \n",
    "    print('epoch [{}/{}], \\tTraining Loss:{:.4f} \\tValidation Loss:{:.4f}'.format(epoch + 1, num_epochs, train_loss, val_loss))\n",
    "    \n",
    "    if val_loss < val_loss_min:\n",
    "        print('Validation loss has decreased ({:.4f}-->{:.4f}). Model saved...'.format(val_loss_min, val_loss))\n",
    "        torch.save(model.state_dict(), 'autoencoder_V2.pt')\n",
    "        val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.decoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config = \"classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50], \tTraining Loss:40.6486 \tValidation Loss:42.2037\n",
      "Validation loss has decreased (inf-->42.2037). Model saved...\n",
      "epoch [2/50], \tTraining Loss:39.4006 \tValidation Loss:38.7358\n",
      "Validation loss has decreased (42.2037-->38.7358). Model saved...\n",
      "epoch [3/50], \tTraining Loss:38.3902 \tValidation Loss:37.5642\n",
      "Validation loss has decreased (38.7358-->37.5642). Model saved...\n",
      "epoch [4/50], \tTraining Loss:37.4150 \tValidation Loss:39.3014\n",
      "epoch [5/50], \tTraining Loss:36.8802 \tValidation Loss:37.0484\n",
      "Validation loss has decreased (37.5642-->37.0484). Model saved...\n",
      "epoch [6/50], \tTraining Loss:36.0556 \tValidation Loss:35.9903\n",
      "Validation loss has decreased (37.0484-->35.9903). Model saved...\n",
      "epoch [7/50], \tTraining Loss:35.4909 \tValidation Loss:35.2170\n",
      "Validation loss has decreased (35.9903-->35.2170). Model saved...\n",
      "epoch [8/50], \tTraining Loss:35.0196 \tValidation Loss:35.3482\n",
      "epoch [9/50], \tTraining Loss:34.3218 \tValidation Loss:34.9070\n",
      "Validation loss has decreased (35.2170-->34.9070). Model saved...\n",
      "epoch [10/50], \tTraining Loss:33.8497 \tValidation Loss:34.4995\n",
      "Validation loss has decreased (34.9070-->34.4995). Model saved...\n",
      "epoch [11/50], \tTraining Loss:33.8280 \tValidation Loss:34.0152\n",
      "Validation loss has decreased (34.4995-->34.0152). Model saved...\n",
      "epoch [12/50], \tTraining Loss:33.1304 \tValidation Loss:34.0334\n",
      "epoch [13/50], \tTraining Loss:33.0723 \tValidation Loss:32.8757\n",
      "Validation loss has decreased (34.0152-->32.8757). Model saved...\n",
      "epoch [14/50], \tTraining Loss:32.6978 \tValidation Loss:32.3386\n",
      "Validation loss has decreased (32.8757-->32.3386). Model saved...\n",
      "epoch [15/50], \tTraining Loss:32.3635 \tValidation Loss:33.0464\n",
      "epoch [16/50], \tTraining Loss:31.9201 \tValidation Loss:32.6396\n",
      "epoch [17/50], \tTraining Loss:31.7662 \tValidation Loss:32.5022\n",
      "epoch [18/50], \tTraining Loss:31.4777 \tValidation Loss:32.3441\n",
      "epoch [19/50], \tTraining Loss:31.5777 \tValidation Loss:32.8073\n",
      "epoch [20/50], \tTraining Loss:31.1204 \tValidation Loss:31.9661\n",
      "Validation loss has decreased (32.3386-->31.9661). Model saved...\n",
      "epoch [21/50], \tTraining Loss:30.7541 \tValidation Loss:31.2527\n",
      "Validation loss has decreased (31.9661-->31.2527). Model saved...\n",
      "epoch [22/50], \tTraining Loss:30.6385 \tValidation Loss:31.7055\n",
      "epoch [23/50], \tTraining Loss:30.3869 \tValidation Loss:32.8215\n",
      "epoch [24/50], \tTraining Loss:30.2220 \tValidation Loss:31.1757\n",
      "Validation loss has decreased (31.2527-->31.1757). Model saved...\n",
      "epoch [25/50], \tTraining Loss:30.0594 \tValidation Loss:30.9666\n",
      "Validation loss has decreased (31.1757-->30.9666). Model saved...\n",
      "epoch [26/50], \tTraining Loss:29.7925 \tValidation Loss:30.2978\n",
      "Validation loss has decreased (30.9666-->30.2978). Model saved...\n",
      "epoch [27/50], \tTraining Loss:29.5721 \tValidation Loss:31.2614\n",
      "epoch [28/50], \tTraining Loss:29.4212 \tValidation Loss:30.5490\n",
      "epoch [29/50], \tTraining Loss:29.5658 \tValidation Loss:29.9665\n",
      "Validation loss has decreased (30.2978-->29.9665). Model saved...\n",
      "epoch [30/50], \tTraining Loss:29.0978 \tValidation Loss:31.4942\n",
      "epoch [31/50], \tTraining Loss:28.9861 \tValidation Loss:30.1986\n",
      "epoch [32/50], \tTraining Loss:28.8883 \tValidation Loss:30.6869\n",
      "epoch [33/50], \tTraining Loss:28.6456 \tValidation Loss:29.8628\n",
      "Validation loss has decreased (29.9665-->29.8628). Model saved...\n",
      "epoch [34/50], \tTraining Loss:28.5528 \tValidation Loss:29.7760\n",
      "Validation loss has decreased (29.8628-->29.7760). Model saved...\n",
      "epoch [35/50], \tTraining Loss:28.4347 \tValidation Loss:29.4703\n",
      "Validation loss has decreased (29.7760-->29.4703). Model saved...\n",
      "epoch [36/50], \tTraining Loss:28.2442 \tValidation Loss:30.2076\n",
      "epoch [37/50], \tTraining Loss:28.1727 \tValidation Loss:29.8009\n",
      "epoch [38/50], \tTraining Loss:28.1112 \tValidation Loss:29.1942\n",
      "Validation loss has decreased (29.4703-->29.1942). Model saved...\n",
      "epoch [39/50], \tTraining Loss:27.9011 \tValidation Loss:31.2379\n",
      "epoch [40/50], \tTraining Loss:28.0284 \tValidation Loss:29.2762\n",
      "epoch [41/50], \tTraining Loss:27.6460 \tValidation Loss:29.3959\n",
      "epoch [42/50], \tTraining Loss:27.6814 \tValidation Loss:29.8192\n",
      "epoch [43/50], \tTraining Loss:27.4845 \tValidation Loss:29.5335\n",
      "epoch [44/50], \tTraining Loss:27.4011 \tValidation Loss:28.8441\n",
      "Validation loss has decreased (29.1942-->28.8441). Model saved...\n",
      "epoch [45/50], \tTraining Loss:27.4148 \tValidation Loss:28.8984\n",
      "epoch [46/50], \tTraining Loss:27.3182 \tValidation Loss:28.5944\n",
      "Validation loss has decreased (28.8441-->28.5944). Model saved...\n",
      "epoch [47/50], \tTraining Loss:27.1909 \tValidation Loss:28.9932\n",
      "epoch [48/50], \tTraining Loss:27.0904 \tValidation Loss:29.8451\n",
      "epoch [49/50], \tTraining Loss:27.1171 \tValidation Loss:28.6974\n",
      "epoch [50/50], \tTraining Loss:26.9212 \tValidation Loss:28.3428\n",
      "Validation loss has decreased (28.5944-->28.3428). Model saved...\n"
     ]
    }
   ],
   "source": [
    "val_loss_min = np.Inf\n",
    "train_loss_arr = []\n",
    "val_loss_arr=[]\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        image = image.view(image.size(0), -1)\n",
    "        #forward\n",
    "        out = model(image)\n",
    "        loss = criterion(out, label)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()*image.size(0)\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    for image, label in val_loader:\n",
    "        image = image.view(image.size(0), -1)\n",
    "        out = model(image)\n",
    "        loss = criterion(out, label)\n",
    "        \n",
    "        val_loss += loss.item()*image.size(0)\n",
    "    \n",
    "    val_loss = val_loss/len(val_loader)    \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    \n",
    "    val_loss_arr.append(val_loss)\n",
    "    train_loss_arr.append(train_loss)\n",
    "    \n",
    "    print('epoch [{}/{}], \\tTraining Loss:{:.4f} \\tValidation Loss:{:.4f}'.format(epoch + 1, num_epochs, train_loss, val_loss))\n",
    "    \n",
    "    if val_loss < val_loss_min:\n",
    "        print('Validation loss has decreased ({:.4f}-->{:.4f}). Model saved...'.format(val_loss_min, val_loss))\n",
    "        torch.save(model.state_dict(), 'autoencoder_V2.pt')\n",
    "        val_loss_min = val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr_x = list(range(1, num_epochs+1))\n",
    "plt.plot(arr_x, train_loss_arr, 'b-', label='train loss')\n",
    "plt.plot(arr_x, val_loss_arr, 'g-', label='validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.231017\n",
      "\n",
      "Test Accuracy of     0: 97% (957/980)\n",
      "Test Accuracy of     1: 98% (1116/1135)\n",
      "Test Accuracy of     2: 93% (970/1032)\n",
      "Test Accuracy of     3: 93% (941/1010)\n",
      "Test Accuracy of     4: 91% (903/982)\n",
      "Test Accuracy of     5: 86% (772/892)\n",
      "Test Accuracy of     6: 96% (922/958)\n",
      "Test Accuracy of     7: 94% (968/1028)\n",
      "Test Accuracy of     8: 91% (887/974)\n",
      "Test Accuracy of     9: 85% (863/1009)\n",
      "\n",
      "Test Accuracy (Overall): 92% (9299/10000)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval() # prep model for evaluation\n",
    "\n",
    "for image, target in test_loader:\n",
    "    image = image.view(image.size(0), -1)\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    test_loss += loss.item()*image.size(0)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.sampler)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Experiments\n",
    "<ul>\n",
    "    <li>Compare both models efficiency in clustering</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
